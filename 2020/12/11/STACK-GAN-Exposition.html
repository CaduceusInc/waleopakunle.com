<h1 id="face-aging-using-conditional-gan">Face Aging Using Conditional GAN</h1>

<p>StackGAN is a two-stage network. Each stage has two generators and two discriminators. StackGAN is made up of many networks, which are as follows:</p>

<ul>
  <li>
    <p><strong>Stack-I GAN</strong>: text encoder, Conditioning Augmentation network, generator network, discriminator network, embedding compressor network</p>
  </li>
  <li>
    <p><strong>Stack-II GAN</strong>: text encoder, Conditioning Augmentation network, generator network, discriminator network, embedding compressor network</p>
  </li>
</ul>

<p>*** INSERT IMAGE OF STACK-GAN ARCHITECTURE ***</p>

<p>The text encoder network</p>

<p>The sole purpose of the text encoder network is to convert a text description (t) to a text embedding</p>

<p>(<img src="assets/img/2020-12-11-STACK-GAN-Exposition/media/image1.png" alt="http://localhost:5001/assets/b202e2a1-36da-4851-8a99-1cf84585df1d.png" />). I won’t train the text encoder network. I will be working with pre-trained text embeddings, but you can train yours by using the steps discussed in this paper: <a href="https://arxiv.org/pdf/1605.05395.pdf">https://arxiv.org/pdf/1605.05395.pdf</a>. The text encoder network encodes a sentence to a 1,024-dimensional text embedding. The text encoder network is common to both of the stages</p>

<p>The conditioning augmentation block</p>

<p>A <strong>conditioning augmentation</strong> (<strong>CA</strong>) network samples random latent variables <img src="assets/img/2020-12-11-STACK-GAN-Exposition/media/image2.png" alt="http://localhost:5001/assets/d86d468c-b92c-41c9-83f1-75baf727847c.png" /> from a distribution, which is represented as <img src="assets/img/2020-12-11-STACK-GAN-Exposition/media/image3.png" alt="http://localhost:5001/assets/cb774d54-76ee-4c94-89a7-94e8b16c4493.png" /></p>

<p>Advantages:</p>

<ul>
  <li>
    <p>It adds randomness to the network.</p>
  </li>
  <li>
    <p>It makes the generator network robust by capturing various objects with various poses and appearances. </p>
  </li>
  <li>
    <p>It produces more image-text pairs. With a higher number of image-text pairs, we can train a robust network that can handle perturbations</p>
  </li>
</ul>

<p>STAGE-1</p>

<p>STAGE-II</p>

<p>TERMS TO READ UP ON</p>

<ul>
  <li>
    <p>diagonal covariance matrix</p>
  </li>
  <li>
    <p>upsampling</p>
  </li>
</ul>
