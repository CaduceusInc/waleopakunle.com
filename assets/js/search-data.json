{
  
    
        "post0": {
            "title": "Fastpages Notebook Blog Post",
            "content": "from pathlib import Path loadpy = Path(&#39;load_covid_data.py&#39;) if not loadpy.exists(): ! wget https://github.com/machine-learning-apps/covid19-dashboard/blob/master/_notebooks/load_covid_data.py . C: Anaconda3 lib site-packages ipykernel_launcher.py:14: FutureWarning: Passing list-likes to .loc or [] with any missing label will raise KeyError in the future, you can use .reindex() as an alternative. See the documentation here: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike . df_50.columns . Index([&#39;country&#39;, &#39;state&#39;, &#39;confirmed&#39;, &#39;type&#39;, &#39;critical_estimate&#39;, &#39;days_since_10&#39;, &#39;recovered&#39;, &#39;deaths&#39;], dtype=&#39;object&#39;) . Analysis for Africa . C: Anaconda3 lib site-packages ipykernel_launcher.py:14: FutureWarning: Passing list-likes to .loc or [] with any missing label will raise KeyError in the future, you can use .reindex() as an alternative. See the documentation here: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike .",
            "url": "https://waleopakunle.com/covid-eda-project/",
            "relUrl": "/covid-eda-project/",
            "date": " • Mar 20, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Progressively Grown Gans",
            "content": "A Summary of Progressive Growing of GANs for improved quality, stability and variation (Pro-GANs) . Before we begin, I thought it would be more insightful (and interesting) if you could first see for yourself what the algorithm produced in this paper is capable of. If you’re interested, please check this youtube video out. . Original Abstract . We describe a new training methodology for generative adversarial networks. The key idea is to grow both the generator and discriminator progressively: starting from a low resolution, we add new layers that model increasingly fine details as training progresses. This both speeds the training up and greatly stabilizes it, allowing us to produce images of unprecedented quality, e.g., CELEBA images at 1024x1024. We also propose a simple way to increase the variation in generated images, and achieve a record inception score of 8:80 in unsupervised CIFAR10. . Additionally, we describe several implementation details that are important for discouraging unhealthy competition between the generator and discriminator. Finally, we suggest a new metric for evaluating GAN results, both in terms of image quality and variation. As an additional contribution, we construct a higher-quality version of the CELEBA dataset. . My Summary . What did they contribute? . The NVIDIA team improved the stability, resolution (image quality) and variation of generated images. They also propose a new metric for evaluating generated images. . What older methods were they improving on? . Resolution (Image quality) | . Durugkar et al. (2016) who use one generator and multiple discriminators concurrently. . Ghosh et al. (2017) who use multiple generators and one discriminator. . Wang et al. (2017), who use multiple discriminators that operate on different spatial resolutions. . Denton et al., 2015; Huang et al., 2016; Zhang et al., 2017 define a generator and discriminator for each level of an image pyramid (Hierarchical GANs). . Variation | . Metz et al., 2016 who unroll the discriminator to regularize its updates. . Zhao et al., 2017 who use a “repelling regularizer” that adds a new loss term to the generator, trying to encourage it to orthogonalize the feature vectors in a minibatch. . Ghosh et al. (2017) who use multiple generators. . Stability | . Ioffe &amp; Szegedy, 2015; Salimans &amp; Kingma, 2016; Ba et al., 2016 and many others tend to use a variant of batch normalization in the generator and discriminator to discourage the escalation of unhealthy competition between the networks. . Issues with existing methods that necessitate this improvement . Autoregressive models have limited applicability because they are slow to evaluate and do not have latent representation although they produce sharp images. Variational autoencoders (VAEs) are easy to train but tend to produce blurry results despite recent advances and this is due to restrictions in the model architecture. GANs produce sharp images, but they do so in fairly small resolutions and somewhat limited variation. Also, training GANs remains notoriously unstable despite recent advances. . Which of the issues were they improving/solving? . Their primary contribution was to develop a training methodology for the training of GANs in which the resolution of the resulting output images could be progressively increased from an initial low-resolution images. They achieved this by progressively adding layers to the networks. . What did they propose to do differently and why? . Change: Use a single generator and discriminator network that are mirror images of each other and always grow in synchrony. All existing layers in both networks remain trainable throughout the training process. . Reason: In previous approaches to training, the networks had to learn both the large-scale structure and fine scale detail of image distributions and this understandably took a long period of time. . Result: . | . Stabilized training sufficiently to enable the reliable synthesis of high resolution images. . | Reduced training time (2 - 6 times faster depending on the output resolution). . | Change: Dynamically setting the weights and scale it at runtime rather than careful initialization . Reason: Previous methods normalize a gradient update by its estimated standard deviation, thus making the update independent of the scale of the parameter. As a result, if some parameters have a larger dynamic range than others, they will take longer to adjust. . Result: Dynamically setting the weights ensures that learning speed is the equal for all weights. . | Change: Normalize the feature vector in each pixel to unit length in the generator after each convolutional layer. . Reason: To disallow the scenario where the magnitudes in the generator and discriminator spiral out of control as a result of competition. . Result: prevents the escalation of signal magnitudes very effectively when needed. . | Change: Considering the multiscale statistical similarity between distributions of local image patches drawn from Laplacian pyramid representations of generated and target images, starting at a low-pass resolution of 16 x 16 pixels. . Reason: Previous methods of evaluating generative performance work reliably in finding large scale mode collapse, but fail to react well to smaller effects such as loss of variation in colors and textures. They also do not directly assess image quality in terms of similarity to the training set. . Result: A new approach for evaluating generated images based on a combination of older methods, including sampling from a Laplacian pyramid and sliced Wasserstein distance (SWD) for estimating statistical similarities. A smaller SWD at a given Laplacian layer indicates that training and generated image samples appear similar in both appearance and variation at the pyramids spatial resolution. . | Change: Use minibatch standard variation to increase variation. . Reason: GANs tend to capture only a subset of variations present in training data and other approaches to tackle this problem are rather cumbersome. . Result: In their experiment, including mini batch standard variation improved the sliced Wasserstein loss. . | . Did their experiments show an improvement? . source: Prograssive growing of GANs for Improved quality, stability and variation. . As can be seen from their results that compare how different training configurations compare in terms of their SWD losses and structural similarities (MS-SIM) of generated images from different datasets (CELEBA and LSUN), progressive GANs have a significantly improved performance. Removing any of the teams new contributions makes the network perform in a handicapped manner as can be seen with and without minibatch standard deviation in (e) and (e*) respectively. . source: Prograssive growing of GANs for Improved quality, stability and variation. . Core Ideas . Older methods had notable weaknesses which were improved on in the paper, including training speed, stability in training and resolution of output images. . | This paper introduced a new methodology for generating high resolution images by progressively increasing the layers in the network. They also tackled mode collapse by using pixel-wise feature normalization and equalized learning rates for all weights. Finally, they increased variation by introducing minibatch standard deviation and proposed a new way for evaluating generated images. . | Advantages of the new method introduced: . | . Decreased training time. With progressively growing GANs most of the iterations are done at lower resolutions, and comparable result quality is often obtained up to 2–6 times faster, depending on the final output resolution. . | More stable GAN training. . | Images are one step closer to photorealism. . | . What the community says about the paper? . #2 Best Image Generation model for CIFAR10 dataset | . Future research areas . Conditional Pro-GANs. . | Increasing resolution threshold. . | Increasing training stability (i.e decreasing the chances of mode collapse) Notably, some work seems to have been done on that here . | . Possible business and other applications . Applications of Pro-GAN to critical domains, such as this one. Where a Pro-GAN architecture was used to generate high resolution synthesized training data for computer-assisted diagnosis, or this one used to generate Gastritis data. . | Generating high resolution example datasets for computer vision tasks. . | Generate high resolution logo (or of anything, really) images for creatives. . | . P.S: If you think of any I may have omitted, please reach out to me. wink . Implementations . You can find the original implementation by Tero Karras here. ALternativels, you can follow this link for a quick start to the colab notebook I set up using his implementation and pretrained network, so you can run it interactively. Create a copy for yourself and hack away. . New Concepts / Terminology . The Inception Score, or IS for short, is an objective metric for evaluating the quality of generated images, specifically synthetic images output by generative adversarial network models. You can read more about how it is calculated and its application here. . Average pooling: Pooling refers to techniques used to downscale / reduce the size of an image gotten from a preceding convolutional layer, in such a way that the information in the image is retained without distortion. Hence, average pooling is just one of the versions of pooling available. You can read all about pooling in this post here. . He’s initializer: A weight initialization method that takes into account the size of the previous layer. The weights are still random, but differ in range depending on the size of the previous layer. . Laplacian pyramid: Used to reconstruct an upsampled image from an image lower in the pyramid (with less resolution). Please checkout this post by Kang and Atul for a very nice explanation and description of the implementation in OpenCV. . Sliced Wasserstein distance (SWD): A modification of the Wasserstein loss function used for increasing the stability of training GANs. You can read the rather involved paper that introduced it here. It leverages on the rather attractive feature of Wasserstein distance while making interesting modifications. . Least Squares Generative Adversarial Network (LSGAN): it’s an extension to the GAN architecture that addresses the problem of vanishing gradients and loss saturation. If you would like to read more aboout it, including how to go about implementing it, check out this blog post. . WGAN-GP or Wasserstein GAN Gradient penalty: It is a modification of the cost function used in WGANs. You can read this article to learn about the limitations of weight clipping in WGANs and the slight modification that makes WGAN-GP approach more desirable. . Training resources used . Network Architecture source: Prograssive growing of GANs for Improved quality, stability and variation. . | Hardware / Compute 8 Tesla V100 GPUs, trained for 4 days to achieve convergence. | | Datasets CELEBA-HQ - A dataset containing HD images of celebrities. 30,000 images were used in total. | LSUN - It contains around one million labeled images for each of 10 scene categories and 20 object categories. | CIFAR10 - It consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. | MNIST - A database of handwritten digits, has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image. It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting. | | Hyperparameters Optimizer: Adam | | . Activation function: leaky ReLU, leakiness of 0.2 . | No learning rate decay or rampdown. . | ncritic = 1 . | Small weight added to discriminator output. . | Adaptive minibatch size depending on the current output resolution. . | Authors of the original paper: Tero Karras (NVIDIA), Timo Aila (NVIDIA), Samuli Laine (NVIDIA), Jaakko Lehtinen (NVIDIA and Aalto University) . That’s it for this post. Thank you for your time! . Please let me know in the comments: . Any new AI research papers you would like me to review. . | Suggestions regarding the content that might need more explanation. . | Anything you want really. . |",
            "url": "https://waleopakunle.com/gans/research%20paper/pro-gan/2020/03/09/progressively-grown-gans.html",
            "relUrl": "/gans/research%20paper/pro-gan/2020/03/09/progressively-grown-gans.html",
            "date": " • Mar 9, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # Title &gt; Awesome summary - toc: true- branch: master- badges: true- comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . #collapse-hide import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . #collapse-show cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # single-value selection over [Major_Genre, MPAA_Rating] pairs # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(movies).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(movies).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=alt.Y(&#39;IMDB_Rating:Q&#39;, axis=alt.Axis(minExtent=30)), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=600, height=400 ) . Example 3: More Tooltips . # select a point for which to provide details-on-demand label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=700, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; df = pd.read_json(movies) # display table with pandas df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://waleopakunle.com/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About",
          "content": "Introduction . Hi there! In case it was not obvious enough from all the name tags, my name is Wale Opakunle. I am a deep learning practitioner, machine learning engineer and data journalist, well, most of the time. Other times, I am just a learning machine confounded by the velocity at which the tech space is accelerating. . I reside in Lagos, Nigeria and I have a first degree in Electrical and Electronics Engineering from the University of Lagos, right down by the Lagos lagoon. . It was there, in my final year in 2018 that I awoke my passion for artificial intelligence. I saw, and still see, numerous untapped paths in which the technology could be harnessed to change my country. In light of this, I began to voraciously read, watch and listen to all materials that so much as mentioned how to architect, produce and distribute products embedded with artificial intelligence. . I dare say that I am still a long way of from understanding all the intricacies - if that is even a thing. However, I have come to learn a whole lot by putting in the effort and I am determined to give back to the community that has helped me grow so much. . It is my deepest desire that I create an awareness of the possibilities that developments in artificial intelligence affords us and by so doing, infect as many as possible within my community with this passion and knowledge, that we may bring about the change we so much desire to see in my country, for ourselves and for posterity. . . Vision for my blog . In light of the above, my blog is dedicated to do the following: . Discuss State of The Art (SOTA) research papers within my field of interest, their implementations as well as possible impacts they could have if harnessed in Nigeria. . | Discuss projects I work on that could be helpful to the community. . | Discuss the various advances in Artificial Intelligence. . | Spurn the audience to contribute to building AI tools (based on all discussions above) for the improvement of Nigeria. . | Contribute to the decentralization and dissemination of AI knowledge in Nigeria. . | Should our interests and passions align, and you wish to collaborate, please do not hesitate to reach out to me. .",
          "url": "https://waleopakunle.com/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  
      ,"page2": {
          "title": "Analytics",
          "content": "This page contains a selection of data science projects I embark on. .",
          "url": "https://waleopakunle.com/analytics",
          "relUrl": "/analytics",
          "date": ""
      }
      
  

  
      ,"page3": {
          "title": "Contact",
          "content": "Quick small favor: . Have you spotted an error I made in my post bants? Do you have suggestions on which papers you would like reviewed next? Would you like to collaborate on a deep learning project? Please send your message to and I will reply as soon as possible! . . Thank you! I really value your feedback. . &lt;/form&gt; .",
          "url": "https://waleopakunle.com/contact",
          "relUrl": "/contact",
          "date": ""
      }
      
  

  
      ,"page4": {
          "title": "",
          "content": "This site documents a fraction of my learning process as I strive to become a world class deep learning practitioner. . Posts .",
          "url": "https://waleopakunle.com/",
          "relUrl": "/",
          "date": ""
      }
      
  

  
      ,"page5": {
          "title": "Papers",
          "content": "This page contains a selection of research papers, pooled from my weekly digest reading list, along with succulent code of course. .",
          "url": "https://waleopakunle.com/papers",
          "relUrl": "/papers",
          "date": ""
      }
      
  

  
      ,"page6": {
          "title": "Projects",
          "content": "This page contains details of deep learning projects I am working on. . Posts .",
          "url": "https://waleopakunle.com/projects",
          "relUrl": "/projects",
          "date": ""
      }
      
  

  
  

  

  
  

  

  
  

  
  

}